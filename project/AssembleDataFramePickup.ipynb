{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as pdsql\n",
    "import pickle\n",
    "\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the pickup_count table and the day_info table\n",
    "conn = psycopg2.connect(\"dbname='nyc_taxi' user='postgres' host='localhost' password='organon'\")\n",
    "cdf = pdsql.read_sql(\"SELECT * FROM pickup_count_nta\", conn, coerce_float=True, params=None)\n",
    "#cdf = pdsql.read_sql(\"SELECT * FROM pickup_count_ct\", conn, coerce_float=True, params=None)\n",
    "#cdf = pdsql.read_sql(\"SELECT * FROM pickup_count_ct_yellow\", conn, coerce_float=True, params=None)\n",
    "#cdf = pdsql.read_sql(\"SELECT * FROM pickup_count_ct_green\", conn, coerce_float=True, params=None)\n",
    "day_info = pdsql.read_sql(\"SELECT * FROM day_info\", conn, coerce_float=True, params=None)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add the rows where count is 0\n",
    "gid_append = []\n",
    "doy_append = []\n",
    "hour_append = []\n",
    "\n",
    "row = 0\n",
    "for gid in range(1, 196): # 195 for NTA, 2166 for CT\n",
    "    for doy in range(1, 366):\n",
    "        for hour in range(24):\n",
    "            if row < len(cdf.index) and\\\n",
    "            cdf.pickup_gid[row] == gid and\\\n",
    "            cdf.pickup_doy[row] == doy and\\\n",
    "            cdf.pickup_hour[row] == hour:\n",
    "                row += 1\n",
    "            else:\n",
    "                gid_append.append(gid)\n",
    "                doy_append.append(doy)\n",
    "                hour_append.append(hour)\n",
    "                \n",
    "    clear_output()\n",
    "    print(\"gid = {0} completed\".format(gid))\n",
    "    sys.stdout.flush()\n",
    "                \n",
    "cdf_append = pd.DataFrame({'pickup_gid': gid_append, 'pickup_doy': doy_append, 'pickup_hour': hour_append},\n",
    "                          columns=['pickup_gid', 'pickup_doy', 'pickup_hour'])\n",
    "cdf_append['count'] = pd.Series([0] * len(gid_append))\n",
    "cdf = cdf.append(cdf_append, ignore_index=True)\n",
    "cdf = cdf.sort_values(by=['pickup_gid', 'pickup_doy', 'pickup_hour'])\n",
    "cdf.index = range(len(cdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add new columns, namely day of the week and the temperature, precipitation, holiday info\n",
    "pickup_dow = (cdf['pickup_doy'] + 2) % 7 # For 2014, Jan. 1 is Wednesday\n",
    "cdf['pickup_dow'] = pickup_dow\n",
    "\n",
    "for col_name in {'temperature', 'precipitation', 'holiday'}:\n",
    "    col = day_info[col_name][cdf['pickup_doy'] - 1]\n",
    "    col.index = range(len(col))\n",
    "    cdf[col_name] = col\n",
    "\n",
    "# Raw dataframe extracted from the original dataset ready for further process\n",
    "cdf_raw = cdf[['pickup_doy', 'count', 'pickup_gid', 'pickup_dow', 'pickup_hour', 'temperature', 'precipitation', 'holiday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cdf_raw.to_pickle('./intermediate_files/dataframes_visualize_nta/data_raw_nta.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = [1,]\n",
    "\n",
    "def get_cdf_delayed(cdf_raw, D):\n",
    "    # Generate dataframe by adding d columns corresponding to the pickup count in the same gid in the previous d hours\n",
    "    # as predictors where d is defined in D\n",
    "    \n",
    "    dm = max(D) # Maximum delay\n",
    "\n",
    "    cols = {key: [] for key in cdf_raw.columns}\n",
    "    cols_count = {'count_{0}'.format(d): [] for d in D}\n",
    "\n",
    "    for gid in range(1, 196):\n",
    "        for key in cols:\n",
    "            cols[key] += cdf_raw[key][(gid-1)*365*24+dm : gid*365*24].values.tolist()\n",
    "\n",
    "        for d in D:\n",
    "            cols_count['count_{0}'.format(d)] += cdf_raw['count'][(gid-1)*365*24+dm-d : gid*365*24-d].values.tolist()\n",
    "        \n",
    "    cdf_with_history = pd.DataFrame({**cols, **cols_count}, columns=cdf_raw.columns.tolist() +\n",
    "                                   ['count_{0}'.format(d) for d in D])\n",
    "    \n",
    "    return cdf_with_history\n",
    "\n",
    "cdf_with_history = get_cdf_delayed(cdf_raw, D)\n",
    "cdf_with_history.to_pickle('./intermediate_files/dataframes_train/data.p')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
