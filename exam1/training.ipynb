{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import pydotplus\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split, KFold, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "\n",
    "from sklearn_bayes.rvm import RVC\n",
    "from sklearn_bayes.logistic.variational_logistic import VariationalLogisticRegression \n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df_exam = pd.read_csv('exam.dat', header=None, sep='[1-4]:', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 3089, d = 5\n",
      "count(g = 0) = 1089, count(g = 1) = 2000\n"
     ]
    }
   ],
   "source": [
    "# Summarize\n",
    "sns.set()\n",
    "plot_scatterplot = sns.pairplot(df_exam, hue=0, vars=np.arange(1, 5))\n",
    "plot_scatterplot.savefig(\"scatterplot.pdf\", dpi=10)\n",
    "\n",
    "print(\"n = {0}, d = {1}\".format(*df_exam.shape))\n",
    "print(\"count(g = 0) = {0}, count(g = 1) = {1}\".format(sum(df_exam[0] < 0.5), sum(df_exam[0] > 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_exam.values[:, 1 :]\n",
    "g = df_exam.values[:, 0]\n",
    "\n",
    "X_train, X_test, g_train, g_test = train_test_split (X, g, test_size = 0.25, random_state=33)\n",
    "\n",
    "mu = np.mean(X_train, axis = 0)\n",
    "sigma = np.std(X_train, axis = 0)\n",
    "X_train = (X_train - mu) / sigma\n",
    "X_test = (X_test - mu) / sigma\n",
    "\n",
    "cv = KFold(X_train.shape[0], n_folds=10, random_state=8) # Generate the cross validation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning logreg...\n",
      "Tuning tree...\n",
      "Tuning knn...\n"
     ]
    }
   ],
   "source": [
    "classifiers = dict()\n",
    "params_key = dict()\n",
    "params_grid = dict()\n",
    "\n",
    "score_train = dict()\n",
    "score_test = dict()\n",
    "score_cv_mean = dict()\n",
    "score_cv_std = dict()\n",
    "\n",
    "# KNN classifier\n",
    "k_range = np.arange(1, 100, 2) # Range of parameter n_neighbors\n",
    "classifiers[\"knn\"] = KNeighborsClassifier()\n",
    "params_key[\"knn\"] = \"n_neighbors\"\n",
    "params_grid[\"knn\"] = dict([(params_key[\"knn\"], k_range), ])\n",
    "\n",
    "# Decision tree classifier\n",
    "depth_range = np.arange(1, 21) # Range of parameter n_neighbors\n",
    "classifiers[\"tree\"] = DecisionTreeClassifier()\n",
    "params_key[\"tree\"] = \"max_depth\"\n",
    "params_grid[\"tree\"] = dict([(params_key[\"tree\"], depth_range), ])\n",
    "\n",
    "# Logistic regresssion \n",
    "C_range = np.logspace(-5, 5, 20) # Range of parameter n_neighbors\n",
    "classifiers[\"logreg\"] = linear_model.LogisticRegression()\n",
    "params_key[\"logreg\"] = \"C\"\n",
    "params_grid[\"logreg\"] = dict([(params_key[\"logreg\"], C_range), ])\n",
    "\n",
    "# Train all the classifiers\n",
    "for classifier in classifiers.keys():\n",
    "    \n",
    "    print(\"Tuning {0}...\".format(classifier))\n",
    "    \n",
    "    grid = GridSearchCV(classifiers[classifier], param_grid=params_grid[classifier], cv=cv , verbose=0, n_jobs=4)\n",
    "    grid.fit(X_train, g_train)\n",
    "    \n",
    "    score_train[classifier] = np.empty(len(params_grid[classifier][params_key[classifier]]), dtype=\"float64\")\n",
    "    score_test[classifier] = np.empty(len(params_grid[classifier][params_key[classifier]]), dtype=\"float64\")\n",
    "    \n",
    "    for idx, p in enumerate(params_grid[classifier][params_key[classifier]]):\n",
    "        classifiers[classifier].set_params(**dict([(params_key[classifier], p), ]))\n",
    "        classifiers[classifier].fit(X_train, g_train)\n",
    "    \n",
    "        score_train[classifier][idx] = classifiers[classifier].score(X_train, g_train)\n",
    "        score_test[classifier][idx] = classifiers[classifier].score(X_test, g_test)\n",
    "        \n",
    "    score_cv_mean[classifier] = [entry[1] for entry in grid.grid_scores_]\n",
    "    score_cv_std[classifier] = [np.std(entry[2]) for entry in grid.grid_scores_] \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the tuning of model parameters\n",
    "axis_font = {'size': '20'}\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16\n",
    "\n",
    "for classifier in classifiers.keys():\n",
    "    plt.figure()\n",
    "\n",
    "    plt.errorbar(params_grid[classifier][params_key[classifier]],\\\n",
    "                 score_cv_mean[classifier], yerr=score_cv_std[classifier],\\\n",
    "                 color='green', linewidth=2, label='10-fold CV', marker='.', markersize=12)\n",
    "    plt.plot(params_grid[classifier][params_key[classifier]],\\\n",
    "             score_train[classifier], color='darkorange', linewidth=2, label='Train', marker='.', markersize=12)\n",
    "    plt.plot(params_grid[classifier][params_key[classifier]],\\\n",
    "             score_test[classifier], color='blue', linewidth=2, label='Test', marker='.', markersize=12)\n",
    "    \n",
    "    plt.xlabel(params_key[classifier], **axis_font)\n",
    "    plt.ylabel('Score', **axis_font)\n",
    "    plt.grid()\n",
    "    plt.legend(prop={'size':16})\n",
    "    plt.savefig('{0}_tuning.pdf'.format(classifier), dpi=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning SVC...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95989650711513586"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The svm classifier with rbf kernel\n",
    "gamma_range = np.logspace(-4, 4, 9)\n",
    "C_range = np.logspace(-4, 4, 9)\n",
    "\n",
    "classifiers[\"svc\"] = SVC(kernel='rbf')\n",
    "params_grid[\"svc\"] = dict(gamma=gamma_range, C=C_range)\n",
    "params_key[\"svc\"] = [\"gamma\", \"C\"]\n",
    "params_grid[\"svc\"] = dict([(\"gamma\", gamma_range), (\"C\", C_range)])\n",
    "\n",
    "print(\"Tuning SVC...\")\n",
    "    \n",
    "grid = GridSearchCV(classifiers[\"svc\"], param_grid=params_grid[\"svc\"], cv=cv, verbose=0, n_jobs=4)\n",
    "grid.fit(X_train, g_train)\n",
    "grid.score(X_test, g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_train[\"svc\"] = np.empty((len(gamma_range), len(C_range)), dtype=\"float64\")\n",
    "score_test[\"svc\"] = np.empty((len(gamma_range), len(C_range)), dtype=\"float64\")\n",
    "\n",
    "for i, gamma in enumerate(gamma_range):\n",
    "    for j, C in enumerate(C_range):\n",
    "        classifiers[\"svc\"].set_params(**dict([(\"gamma\", gamma), (\"C\", C)]))\n",
    "        classifiers[\"svc\"].fit(X_train, g_train)\n",
    "        \n",
    "        score_train[\"svc\"][i][j] = classifiers[\"svc\"].score(X_train, g_train)\n",
    "        score_test[\"svc\"][i][j] = classifiers[\"svc\"].score(X_test, g_test)\n",
    "        \n",
    "score_cv_mean[\"svc\"] = np.reshape(np.array([entry[1] for entry in grid.grid_scores_]),\\\n",
    "                                  (len(gamma_range), len(C_range)),\\\n",
    "                                  order='F')\n",
    "score_cv_std[\"svc\"] = np.reshape(np.array([np.std(entry[2]) for entry in grid.grid_scores_]),\\\n",
    "                                  (len(gamma_range), len(C_range)),\\\n",
    "                                  order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "axis_font = {'size': '16'}\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex = True, sharey = True)\n",
    "\n",
    "caxes = [None] * 4\n",
    "im0 = axes[0][0].imshow(score_train[\"svc\"], interpolation='none', cmap = cm.autumn, aspect='auto', origin='lower', vmin=0.6, vmax=1)\n",
    "axes[0][0].set_title('Train')\n",
    "axes[0][1].imshow(score_test[\"svc\"], interpolation='none', cmap = cm.autumn, aspect='auto', origin='lower', vmin=0.6, vmax=1)\n",
    "axes[0][1].set_title('Test')\n",
    "axes[1][0].imshow(score_cv_mean[\"svc\"], interpolation='none', cmap = cm.autumn, aspect='auto', origin='lower', vmin=0.6, vmax=1)\n",
    "axes[1][0].set_title('10-fold CV mean')\n",
    "im1 = axes[1][1].imshow(score_cv_std[\"svc\"], interpolation='none', cmap = cm.winter, aspect='auto', origin='lower', vmin=0, vmax=0.03)\n",
    "axes[1][1].set_title('10-fold CV std')\n",
    "\n",
    "for row in range(2):\n",
    "    axes[row][0].set_ylabel('$\\log\\gamma$', **axis_font)     \n",
    "    axes[row][0].set_yticks(np.arange(len(gamma_range)))\n",
    "    axes[row][0].set_yticklabels(np.log10(gamma_range).astype(int))\n",
    "for col in range(2):\n",
    "    axes[1][col].set_xlabel('$\\log C$', **axis_font)\n",
    "    axes[1][col].set_xticks(np.arange(len(C_range)))\n",
    "    axes[1][col].set_xticklabels(np.log10(C_range).astype(int))\n",
    "    axes[1][col].grid(True)\n",
    "    \n",
    "fig.subplots_adjust(right=0.65)\n",
    "cbar_ax0 = fig.add_axes([0.7, 0.15, 0.05, 0.7])\n",
    "plt.colorbar(im0, cax=cbar_ax0)  \n",
    "\n",
    "cbar_ax1 = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "plt.colorbar(im1, cax=cbar_ax1)\n",
    "\n",
    "plt.savefig('svc_tuning.pdf', dpi=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9745250431778929, 0.96119016817593794)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers[\"rfc\"]  = RandomForestClassifier(n_estimators=10, max_depth=3) # Random forest classifier\n",
    "classifiers[\"rfc\"].fit(X_train, g_train)\n",
    "        \n",
    "score_train[\"rfc\"] = classifiers[\"rfc\"].score(X_train, g_train)\n",
    "score_test[\"rfc\"] = classifiers[\"rfc\"].score(X_test, g_test)\n",
    "\n",
    "score_train[\"rfc\"], score_test[\"rfc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96636481241914618"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers[\"rvc\"] = RVC(kernel = 'rbf', gamma = 1)\n",
    "classifiers[\"rvc\"].fit(X_train, g_train)\n",
    "classifiers[\"rvc\"].score(X_test, g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94437257438551103"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers[\"vlr\"] = VariationalLogisticRegression()\n",
    "classifiers[\"vlr\"].fit(X_train, g_train)\n",
    "classifiers[\"vlr\"].score(X_test, g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier tree...\n",
      "Classifier svc...\n",
      "Classifier vlr...\n",
      "Classifier rvc...\n",
      "Classifier logreg...\n",
      "Classifier rfc...\n",
      "Classifier knn...\n",
      "False positive:  {'tree': 0.085106382978723402, 'rfc': 0.063829787234042548, 'vlr': 0.067375886524822695, 'rvc': 0.067375886524822695, 'logreg': 0.067375886524822695, 'svc': 0.056737588652482268, 'knn': 0.063829787234042548}\n",
      "False negative:  {'tree': 0.026476578411405296, 'rfc': 0.022403258655804479, 'vlr': 0.048879837067209775, 'rvc': 0.022403258655804479, 'logreg': 0.048879837067209775, 'svc': 0.030549898167006109, 'knn': 0.030549898167006109}\n",
      "Precision:  {'tree': 0.91960704052394593, 'rfc': 0.93870927474722254, 'vlr': 0.93384767023818804, 'rvc': 0.93552377858717672, 'logreg': 0.93384767023818804, 'svc': 0.94471032036484437, 'knn': 0.9382260431956384}\n",
      "Recall:  {'tree': 0.97352342158859473, 'rfc': 0.9775967413441955, 'vlr': 0.95112016293279023, 'rvc': 0.9775967413441955, 'logreg': 0.95112016293279023, 'svc': 0.96945010183299385, 'knn': 0.96945010183299385}\n",
      "Score:  {'tree': 0.95213454075032344, 'rfc': 0.96248382923674003, 'vlr': 0.94437257438551103, 'rvc': 0.96119016817593794, 'logreg': 0.94437257438551103, 'svc': 0.95989650711513586, 'knn': 0.95730918499353168}\n"
     ]
    }
   ],
   "source": [
    "# Train the best classifier for each algorithms and evaluate their performances\n",
    "fpr = dict() # False positive rate\n",
    "fnr = dict() # False negative rate\n",
    "precision = dict() # Precision\n",
    "recall = dict() # Recall\n",
    "score = dict() # Test score\n",
    "\n",
    "classifiers[\"knn\"].set_params(n_neighbors=15)\n",
    "classifiers[\"tree\"].set_params(max_depth=3)\n",
    "classifiers[\"logreg\"].set_params(C=1)\n",
    "classifiers[\"svc\"].set_params(C=1, gamma=1)\n",
    "classifiers[\"rfc\"].set_params(max_depth=3)\n",
    "classifiers[\"rvc\"].set_params(kernel = 'rbf', gamma = 1)\n",
    "classifiers[\"vlr\"].set_params()\n",
    "\n",
    "for classifier in classifiers.keys():\n",
    "    classifiers[classifier].fit(X_train, g_train)\n",
    "    g_score = classifiers[classifier].predict(X_test)\n",
    "    \n",
    "    fpr[classifier], fnr[classifier] = sum((g_test==0) * (g_score==1)) / sum(g_test==0),\\\n",
    "                                       sum((g_test==1) * (g_score==0)) / sum(g_test==1)\n",
    "        \n",
    "    \n",
    "    precision[classifier], recall[classifier] = (1 - fnr[classifier]) /\\\n",
    "                                                (1 - fnr[classifier] + fpr[classifier]),\\\n",
    "                                                (1 - fnr[classifier])/\\\n",
    "                                                (1 - fnr[classifier] + fnr[classifier])\n",
    "    score[classifier] = classifiers[classifier].score(X_test, g_test)\n",
    "    \n",
    "    print(\"Classifier {0}...\".format(classifier))\n",
    "\n",
    "print('False positive: ', fpr)\n",
    "print('False negative: ', fnr)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('Score: ', score)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the tree structure\n",
    "dot_data = StringIO() \n",
    "\n",
    "export_graphviz(classifiers[\"tree\"], out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                class_names=['0', '1'],\n",
    "                special_characters=True)  \n",
    "pydotplus.graph_from_dot_data(dot_data.getvalue()).write_pdf('tree.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=SVC(C=10000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcbag = BaggingClassifier(SVC(kernel='rbf', gamma=0.1, C=10000))\n",
    "svcbag.fit(X_train, g_train)\n",
    "svcbag.score(X_test, g_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers[\"tree\"].mu = mu # Mean and standard deviation used to do normalization\n",
    "classifiers[\"tree\"].sigma = sigma\n",
    "\n",
    "pickle.dump(classifiers[\"tree\"], open(\"classifier.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
